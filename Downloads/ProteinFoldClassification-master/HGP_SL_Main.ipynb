{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HGP_SL_Main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3cW_VgVJmgg",
        "outputId": "beb6fce7-fcfa-4ab0-b922-ed72950459d9"
      },
      "source": [
        "# !pip install torch-geometric \\\n",
        "#   torch-sparse \\\n",
        "#   torch-scatter \\\n",
        "#   torch-cluster \\\n",
        "#   -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Collecting torch-scatter\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_scatter-2.0.7-cp37-cp37m-linux_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 2.5MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.7\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Collecting torch-sparse\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_sparse-0.6.10-cp37-cp37m-linux_x86_64.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.10\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Collecting torch-cluster\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (926kB)\n",
            "\u001b[K     |████████████████████████████████| 931kB 4.5MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.5.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Collecting torch-spline-conv\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (382kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/61/b3f23832120c404673f6759008312ffe8269524a29bf6116d9980e44517b/torch_geometric-1.7.2.tar.gz (222kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.5.1)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.15)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (1.15.0)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.7.2-cp37-none-any.whl size=388143 sha256=c08c14289d76dc1cd5b421ae8524063a03a6d070f1aa6852aa902699a999e24b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/66/5b/ad17ef7f04b7c425dc6930daac160c3747231b0d65f9ac7972\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.0 rdflib-5.0.0 torch-geometric-1.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNXa0Z82Jvo1"
      },
      "source": [
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from models import Model\n",
        "from torch.utils.data import random_split\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import TUDataset\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import make_interp_spline\n",
        "import random\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"-f\")\n",
        "parser.add_argument('--seed', type=int, default=777, help='random seed')\n",
        "parser.add_argument('--batch_size', type=int, default=512, help='batch size')\n",
        "parser.add_argument('--lr', type=float, default=0.005, help='learning rate')\n",
        "parser.add_argument('--weight_decay', type=float, default=0.001, help='weight decay')\n",
        "parser.add_argument('--nhid', type=int, default=512, help='hidden size')\n",
        "parser.add_argument('--sample_neighbor', type=bool, default=True, help='whether sample neighbors')\n",
        "parser.add_argument('--sparse_attention', type=bool, default=True, help='whether use sparse attention')\n",
        "parser.add_argument('--structure_learning', type=bool, default=True, help='whether perform structure learning')\n",
        "parser.add_argument('--pooling_ratio', type=float, default=0.5, help='pooling ratio')\n",
        "parser.add_argument('--dropout_ratio', type=float, default=0.1, help='dropout ratio')\n",
        "parser.add_argument('--lamb', type=float, default=1.0, help='trade-off parameter')\n",
        "#parser.add_argument('--dataset', type=str, default='PROTEINS', help='DD/PROTEINS/NCI1/NCI109/Mutagenicity/ENZYMES')\n",
        "parser.add_argument('--device', type=str, default='cuda:0', help='specify cuda devices')\n",
        "parser.add_argument('--epochs', type=int, default=1000, help='maximum number of epochs')\n",
        "parser.add_argument('--patience', type=int, default=1000, help='patience for early stopping')\n",
        "\n",
        "args = parser.parse_args()\n",
        "torch.manual_seed(args.seed)\n",
        "torch.cuda.set_device(args.device)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(args.seed)\n",
        "\n",
        "with open(\"/content/all_betagraph_.txt\",\"rb\") as f:\n",
        "    traindataset = pickle.load(f,encoding=\"latin1\")\n",
        "with open(\"/content/all_betagraph_.txt\",\"rb\") as f:\n",
        "    testdataset = pickle.load(f,encoding=\"latin1\")\n",
        "#testdataset =testdataset[600:728]\n",
        "#print(testdataset)\n",
        "#dataset = TUDataset(os.path.join('data', args.dataset), name=args.dataset, use_node_attr=True)\n",
        "traindataset=traindataset\n",
        "args.num_classes = 179\n",
        "args.num_features = 2\n",
        "\n",
        "print(args)\n",
        "\n",
        "#num_training = int(len(dataset) * 1.0)\n",
        "num_val = len(testdataset)-int(len(testdataset) * 0.2)\n",
        "print(num_val)\n",
        "#num_test = len(dataset) - (num_training + num_val)\n",
        "print(testdataset[1])\n",
        "\n",
        "training_set=random.sample(traindataset,len(traindataset))\n",
        "\n",
        "test_set=random.sample(testdataset,len(testdataset))\n",
        "validation_set=test_set\n",
        "print(test_set[1])\n",
        "test_set=test_set[num_val:]\n",
        "#test_set=random.sample(test_set,len(test_set))\n",
        "print(len(test_set))\n",
        "train_loader = DataLoader(training_set, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "print(len(train_loader.dataset))\n",
        "val_loader = DataLoader(validation_set, batch_size=args.batch_size, shuffle=False)\n",
        "print(len(val_loader.dataset))\n",
        "test_loader = DataLoader(test_set, batch_size=args.batch_size, shuffle=False)\n",
        "print(len(test_loader.dataset))\n",
        "model = Model(args).to(args.device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "\n",
        "\n",
        "def train():\n",
        "    min_loss = 0\n",
        "    patience_cnt = 0\n",
        "    val_loss_values = []\n",
        "    best_epoch = 0\n",
        "    acc_trainset=[]\n",
        "    acc_testset=[]\n",
        "    t = time.time()\n",
        "    best_acc = 0\n",
        "    model.train()\n",
        "    for epoch in range(args.epochs):\n",
        "        loss_train = 0.0\n",
        "        correct = 0\n",
        "        for i, data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            #data=data[0]\n",
        "                        \n",
        "            data = data.to(args.device)\n",
        "            #i = i.view(args.batch_size)\n",
        "            out = model(data)\n",
        "            #print(out)\n",
        "            #print(data.y)\n",
        "            loss = F.nll_loss(out, data.y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            #optimizer.zero_grad()\n",
        "            loss_train += loss.item()\n",
        "            pred = out.max(dim=1)[1]\n",
        "            correct += pred.eq((data.y)).sum().item()\n",
        "        acc_train = correct / len(train_loader.dataset)\n",
        "        acc_val, loss_val = compute_test(val_loader)\n",
        "        test_acc, test_loss = compute_test(test_loader)\n",
        "        if(test_acc>best_acc):\n",
        "          best_acc=test_acc\n",
        "        acc_trainset.append(acc_train)\n",
        "        acc_testset.append(test_acc)\n",
        "    #print('acc_val: {:.6f}'.format(acc_val), 'time: {:.6f}s'.format(time.time() - t),)\n",
        "        print('Epoch: {:04d}'.format(epoch + 1), 'loss_train: {:.6f}'.format(loss_train),\n",
        "              'acc_train: {:.6f}'.format(acc_train),\n",
        "              'Test set results, loss = {:.6f}, accuracy = {:.6f}'.format(test_loss, test_acc))\n",
        "\n",
        "        val_loss_values.append(loss_val)\n",
        "        torch.save(model.state_dict(), '{}.pth'.format(epoch))\n",
        "        if val_loss_values[-1] < min_loss:\n",
        "            min_loss = val_loss_values[-1]\n",
        "            best_epoch = epoch\n",
        "            patience_cnt = 0\n",
        "        else:\n",
        "            patience_cnt += 1\n",
        "\n",
        "        if patience_cnt == args.patience:\n",
        "            break\n",
        "\n",
        "        files = glob.glob('*.pth')\n",
        "        for f in files:\n",
        "            epoch_nb = int(f.split('.')[0])\n",
        "            if epoch_nb < best_epoch:\n",
        "                os.remove(f)\n",
        "\n",
        "    files = glob.glob('*.pth')\n",
        "    for f in files:\n",
        "        epoch_nb = int(f.split('.')[0])\n",
        "        if epoch_nb > best_epoch:\n",
        "            os.remove(f)\n",
        "    print('Optimization Finished! Total time elapsed: {:.6f}'.format(time.time() - t))\n",
        "    test_acc, test_loss = compute_test(test_loader)\n",
        "    plt.title('train set accuracy')\n",
        "    plt.scatter([range(0,1000)],acc_trainset)\n",
        "    plt.show()\n",
        "    plt.title('Test set accuracy')\n",
        "    plt.scatter([range(0,1000)],acc_testset)\n",
        "    plt.show()\n",
        "    print('Test set results, loss = {:.6f}, accuracy = {:.6f}'.format(test_loss, best_acc))\n",
        "    return best_epoch\n",
        "\n",
        "\n",
        "def compute_test(loader):\n",
        "    model.eval()\n",
        "    correct = 0.0\n",
        "    loss_test = 0.0\n",
        "    datalist=[]\n",
        "    predlist=[]\n",
        "    for data in loader:\n",
        "        data = data.to(args.device)\n",
        "        datalist.append(data.y)\n",
        "        out = model(data)\n",
        "\n",
        "        pred = out.max(dim=1)[1]\n",
        "        predlist.append(pred)\n",
        "        correct += pred.eq(data.y).sum().item()\n",
        "        loss_test += F.nll_loss(out, data.y).item()\n",
        "        #print(correct)\n",
        "    return correct / len(loader.dataset), loss_test\n",
        "\n",
        "def compute_pred(loader):\n",
        "    model.eval()\n",
        "    correct = 0.0\n",
        "    loss_test = 0.0\n",
        "    datalist=[]\n",
        "    predlist=[]\n",
        "    for data in loader:\n",
        "        data = data.to(args.device)\n",
        "        datalist.append(data.y)\n",
        "        out = model(data)\n",
        "\n",
        "        pred = out.max(dim=1)[1]\n",
        "        predlist.append(pred)\n",
        "        correct += pred.eq(data.y).sum().item()\n",
        "        loss_test += F.nll_loss(out, data.y).item()\n",
        "       #print(correct)\n",
        "    #loss_test += F.nll_loss(out, data.y).item()\n",
        "    return datalist, predlist\n",
        "if __name__ == '__main__':\n",
        "    # Model training\n",
        "    best_model = train()\n",
        "    \n",
        "    # Restore best model for test set\n",
        "    #model.load_state_dict(torch.load('{}.pth'.format(best_model)))\n",
        "    test_acc, test_loss = compute_test(test_loader)\n",
        "    print('Test set results, loss = {:.6f}, accuracy = {:.6f}'.format(test_loss, test_acc))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}